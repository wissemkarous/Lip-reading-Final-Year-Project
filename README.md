# Lip-Reading Final Year Project :

This deep learning project focuses on Lip Reading, a technique for understanding speech by visually interpreting the movements of the lips. Our implementation utilizes deep learning and can be beneficial for individuals who are hard of hearing or for extracting information from videos without sound.
# Project Presentation :
https://github.com/wissemkarous/Lip-reading-Final-Year-Project/assets/115191512/1e81dc7b-084d-4202-9e4a-480703d21366


## Lip2AudSpec: Speech Reconstruction from Silent Lip Movements Video ğŸ“¹
![Lip2AudSpec](https://github.com/wissemkarous/Lip-readingPFA/assets/115191512/b1a8a17b-da29-4424-9e5c-b3f51dd07a27)

## Objective ğŸ¯
Lip Reading is language-dependent, and in this project, we have chosen Hangul as the language for Lip Reading implementation.

## Model-Graph: 
![Model](https://github.com/wissemkarous/Lip-reading-Final-Year-Project/assets/115191512/f5c87939-e3cc-407a-aa82-63bd553b8f4d)

## Loss Results After Using CTC Layer ğŸ“‰ : 
- **For 20 Epochs:** <br>
  ![20 Epochs](https://github.com/wissemkarous/Lip-reading-Final-Year-Project/assets/115191512/7f546150-bac9-4ac2-aa03-2a06a7cbc9d3)

- **For 40 Epochs:** <br>
  ![40 Epochs](https://github.com/wissemkarous/Lip-reading-Final-Year-Project/assets/115191512/6c5282e6-7276-4a27-8ece-fa31c3c5a576)

# Author ğŸ§‘â€ğŸ’» :
Wissem Karous 
Reach me at: <br>
ğŸ“§wissemkar203@gmail.com

